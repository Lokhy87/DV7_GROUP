{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WEB SCRAPPING TRANSFERMARKT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lxml\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL de la página de Mbappé en Transfermarkt\n",
    "url = 'https://www.transfermarkt.es/kylian-mbappe/profil/spieler/342229'\n",
    "\n",
    "# Hacemos la solicitud con un user-agent válido para no ser bloqueados\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.83 Safari/537.36'\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre: Kylian Mbappé\n"
     ]
    }
   ],
   "source": [
    "# Extraer el nombre completo\n",
    "try:\n",
    "    headline_wrapper = soup.find('h1', class_='data-header__headline-wrapper')\n",
    "    numero = headline_wrapper.find('span', class_='data-header__shirt-number').text.strip()\n",
    "    nombre = headline_wrapper.text.replace(numero, \"\").strip()\n",
    "except AttributeError:\n",
    "    nombre = \"Nombre no encontrado\"\n",
    "\n",
    "# Imprimir el nombre del jugador\n",
    "print(f\"Nombre: {nombre}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equipo: Real Madrid\n",
      "Liga: LaLiga\n",
      "Fecha de Fichaje: 01/07/2024\n",
      "Contrato hasta: 30/06/2029\n"
     ]
    }
   ],
   "source": [
    "# Extraer la información del fichaje\n",
    "try:\n",
    "    club_info = soup.find('div', class_='data-header__club-info')\n",
    "    \n",
    "    # Nombre del equipo\n",
    "    equipo = club_info.find('span', class_='data-header__club').find('a').text.strip()\n",
    "    \n",
    "    # Liga\n",
    "    liga = club_info.find('span', class_='data-header__league').text.strip()\n",
    "    \n",
    "    # Fecha de fichaje\n",
    "    fecha_fichaje = club_info.find_all('span', class_='data-header__label')[1].find('span', class_='data-header__content').text.strip()\n",
    "    \n",
    "    # Contrato hasta\n",
    "    contrato_hasta = club_info.find_all('span', class_='data-header__label')[2].find('span', class_='data-header__content').text.strip()\n",
    "\n",
    "except AttributeError:\n",
    "    equipo = liga = fecha_fichaje = contrato_hasta = \"Información no encontrada\"\n",
    "\n",
    "# Imprimir la información del fichaje\n",
    "print(f\"Equipo: {equipo}\")\n",
    "print(f\"Liga: {liga}\")\n",
    "print(f\"Fecha de Fichaje: {fecha_fichaje}\")\n",
    "print(f\"Contrato hasta: {contrato_hasta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fecha de Nacimiento: 20/12/1998 (25)\n"
     ]
    }
   ],
   "source": [
    "# Extraer la fecha de nacimiento y edad\n",
    "try:\n",
    "    birth_date_span = soup.find('span', {'itemprop': 'birthDate'})\n",
    "    if birth_date_span:\n",
    "        fecha_nacimiento = birth_date_span.get_text(strip=True)\n",
    "    else:\n",
    "        fecha_nacimiento = \"Fecha de nacimiento no encontrada\"\n",
    "except AttributeError:\n",
    "    fecha_nacimiento = \"Fecha de nacimiento no encontrada\"\n",
    "\n",
    "# Imprimir la fecha de nacimiento\n",
    "print(f\"Fecha de Nacimiento: {fecha_nacimiento}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lugar de Nacimiento: Paris\n"
     ]
    }
   ],
   "source": [
    "# Extraer el lugar de nacimiento\n",
    "try:\n",
    "    birth_place_span = soup.find('span', {'itemprop': 'birthPlace'})\n",
    "    if birth_place_span:\n",
    "        lugar_nacimiento = birth_place_span.get_text(strip=True)\n",
    "    else:\n",
    "        lugar_nacimiento = \"Lugar de nacimiento no encontrado\"\n",
    "except AttributeError:\n",
    "    lugar_nacimiento = \"Lugar de nacimiento no encontrado\"\n",
    "\n",
    "print(f\"Lugar de Nacimiento: {lugar_nacimiento}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nacionalidad: Francia\n"
     ]
    }
   ],
   "source": [
    "# Extraer la nacionalidad\n",
    "try:\n",
    "    nationality_span = soup.find('span', {'itemprop': 'nationality'})\n",
    "    if nationality_span:\n",
    "        nacionalidad = nationality_span.get_text(strip=True).split('\\n')[-1].strip()\n",
    "    else:\n",
    "        nacionalidad = \"Nacionalidad no encontrada\"\n",
    "except AttributeError:\n",
    "    nacionalidad = \"Nacionalidad no encontrada\"\n",
    "\n",
    "print(f\"Nacionalidad: {nacionalidad}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Altura: 1,78 m\n"
     ]
    }
   ],
   "source": [
    "# Extraer la altura\n",
    "try:\n",
    "    height_span = soup.find('span', {'itemprop': 'height'})\n",
    "    if height_span:\n",
    "        altura = height_span.get_text(strip=True)\n",
    "    else:\n",
    "        altura = \"Altura no encontrada\"\n",
    "except AttributeError:\n",
    "    altura = \"Altura no encontrada\"\n",
    "\n",
    "print(f\"Altura: {altura}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posición: Delantero centro\n"
     ]
    }
   ],
   "source": [
    "# Extraer la posición\n",
    "try:\n",
    "    # Encontrar todos los <ul> con la clase 'data-header__items'\n",
    "    uls = soup.find_all('ul', class_='data-header__items')\n",
    "    if len(uls) > 1:\n",
    "        # Dentro del segundo <ul>, buscar el <li> que contiene 'Posición:'\n",
    "        position_li = next((li for li in uls[1].find_all('li', class_='data-header__label') \n",
    "                            if 'Posición:' in li.get_text()), None)\n",
    "        if position_li:\n",
    "            position_span = position_li.find('span', class_='data-header__content')\n",
    "            #posicion = get_text_or_default(position_span)\n",
    "        else:\n",
    "            posicion = \"Posición no encontrada\"\n",
    "    else:\n",
    "        posicion = \"Posición no encontrada\"\n",
    "except AttributeError:\n",
    "    posicion = \"Posición no encontrada\"\n",
    "\n",
    "# Imprimir la posición\n",
    "print(f\"Posición: {posicion}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selección: Francia\n"
     ]
    }
   ],
   "source": [
    "# Extraer la selección\n",
    "try:\n",
    "    # Encontrar el <li> que contiene 'Selección:'\n",
    "    selection_li = next((li for li in soup.find_all('li', class_='data-header__label') \n",
    "                         if 'Selección:' in li.get_text()), None)\n",
    "    if selection_li:\n",
    "        selection_span = selection_li.find('span', class_='data-header__content')\n",
    "        if selection_span:\n",
    "            # Extraer y limpiar el texto de la selección\n",
    "            selection = selection_span.get_text(strip=True)\n",
    "            # Limpiar el texto de posibles elementos adicionales (imágenes y enlaces)\n",
    "            selection = ' '.join(selection.split())\n",
    "        else:\n",
    "            selection = \"Selección no encontrada\"\n",
    "    else:\n",
    "        selection = \"Selección no encontrada\"\n",
    "except AttributeError:\n",
    "    selection = \"Selección no encontrada\"\n",
    "\n",
    "# Imprimir la selección\n",
    "print(f\"Selección: {selection}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partidos Internacionales: 84\n",
      "Goles: 48\n"
     ]
    }
   ],
   "source": [
    "# Extraer partidos internacionales y goles\n",
    "try:\n",
    "    # Encontrar el <li> que contiene 'Partidos internac./goles:'\n",
    "    stats_li = next((li for li in soup.find_all('li', class_='data-header__label') \n",
    "                     if 'Partidos internac./goles:' in li.get_text()), None)\n",
    "    if stats_li:\n",
    "        # Encontrar todos los <a> dentro del <li> correspondiente\n",
    "        stats_links = stats_li.find_all('a', class_='data-header__content--highlight')\n",
    "        if len(stats_links) == 2:\n",
    "            partidos = stats_links[0].get_text(strip=True)\n",
    "            goles = stats_links[1].get_text(strip=True)\n",
    "        else:\n",
    "            partidos = \"No disponible\"\n",
    "            goles = \"No disponible\"\n",
    "    else:\n",
    "        partidos = goles = \"Partidos y goles no encontrados\"\n",
    "except AttributeError:\n",
    "    partidos = goles = \"Partidos y goles no encontrados\"\n",
    "\n",
    "print(f\"Partidos Internacionales: {partidos}\")\n",
    "print(f\"Goles: {goles}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor de Mercado: 180,00 mill. €\n",
      "Última Revisión: 03/06/2024\n"
     ]
    }
   ],
   "source": [
    "# Extraer el valor del mercado y la última revisión\n",
    "try:\n",
    "    # Buscar el <div> que contiene el valor del mercado\n",
    "    market_value_div = soup.find('div', class_='data-header__box--small')\n",
    "    if market_value_div:\n",
    "        # Extraer el valor del mercado\n",
    "        market_value_span = market_value_div.find('span', class_='waehrung')\n",
    "        market_value_text = market_value_div.get_text(separator=' ', strip=True)\n",
    "        \n",
    "        # Limpiar el valor del mercado de la última revisión\n",
    "        if market_value_span:\n",
    "            market_value = market_value_text.split('Última revisión:')[0].strip()\n",
    "        else:\n",
    "            market_value = market_value_text.split('Última revisión:')[0].strip()\n",
    "        \n",
    "        # Extraer la última revisión\n",
    "        last_update = market_value_text.split('Última revisión:')[-1].strip() if 'Última revisión:' in market_value_text else \"Última revisión no encontrada\"\n",
    "    else:\n",
    "        market_value = \"Valor de mercado no encontrado\"\n",
    "        last_update = \"Última revisión no encontrada\"\n",
    "except AttributeError:\n",
    "    market_value = \"Valor de mercado no encontrado\"\n",
    "    last_update = \"Última revisión no encontrada\"\n",
    "\n",
    "# Imprimir la información extraída\n",
    "print(f\"Valor de Mercado: {market_value}\")\n",
    "print(f\"Última Revisión: {last_update}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
